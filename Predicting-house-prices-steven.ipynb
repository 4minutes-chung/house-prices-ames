{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Project Summary\n**Notes:**\n- ANALYSIS_NOTES.md to provide deeper economist edge intuition and interpretation.\n\n**Motivation:**\n- Using accessible raw dataset to practice applied prediction with proper CV and data cleaning in Python.\n\n**Goal:**\n- Predict house prices using structured housing data and compare linear, regularized, and ML tree-based models.\n\n**Methodology:**\n- Log-transformed target: Log(SalePrice)\n- Data cleaning and encoding\n- Evaluates models with 10-fold cross-validation RMSE\n- Models: OLS, Ridge, Lasso, Elastic Net, Random Forest, Gradient Boosting, XGBoost\n\n**Key Findings:**\n- XGBoost achieves the lowest and most stable CV RMSE (~0.118)","metadata":{}},{"cell_type":"code","source":"# To install packages\n## %pip install numpy pandas matplotlib seaborn scikit-learn xgboost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:44:39.160561Z","iopub.execute_input":"2025-12-30T02:44:39.161049Z","iopub.status.idle":"2025-12-30T02:44:39.166358Z","shell.execute_reply.started":"2025-12-30T02:44:39.161001Z","shell.execute_reply":"2025-12-30T02:44:39.165419Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ntrain_file_path = \"../input/house-prices-advanced-regression-techniques/train.csv\"\ntrain = pd.read_csv(train_file_path)\ntest_file_path = \"../input/house-prices-advanced-regression-techniques/test.csv\"\ntest = pd.read_csv(test_file_path)\n","metadata":{"_uuid":"3b7218fe-57d7-453b-85c6-7034844612eb","_cell_guid":"79bdedcb-ca4c-46ae-b49f-5516ef38f567","trusted":true,"_execution_state":"idle","execution":{"iopub.status.busy":"2025-12-30T02:44:39.168145Z","iopub.execute_input":"2025-12-30T02:44:39.168457Z","iopub.status.idle":"2025-12-30T02:44:39.587457Z","shell.execute_reply.started":"2025-12-30T02:44:39.168428Z","shell.execute_reply":"2025-12-30T02:44:39.586546Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Data Load and Inspect","metadata":{"_uuid":"2017d2b0-751d-4829-8c13-ee046340e395","_cell_guid":"10c92efb-fb4b-457d-b7f2-ea3fd16858f8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"series = train.isna().sum()\nmissing_count = series.to_frame(name=\"n_missing\")\n\n# percentage missing\nn_rows = train.shape[0]\n\nmissing_count[\"pct_missing\"] = missing_count[\"n_missing\"]/ n_rows * 100\n\nmissing_count = missing_count[missing_count[\"n_missing\"] > 0]\n\n# sort descending\nmissing_count = missing_count.sort_values(\n    by=\"pct_missing\",\n    ascending=False\n)\n\nmissing_count = missing_count.reset_index().rename(\n    columns={\"index\": \"variable\"}\n)","metadata":{"_uuid":"2de35c21-d651-4d93-b95a-db4a4c288d11","_cell_guid":"53499d05-0532-4ab2-af54-a777ce04c962","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:44:39.588413Z","iopub.execute_input":"2025-12-30T02:44:39.588667Z","iopub.status.idle":"2025-12-30T02:44:39.603023Z","shell.execute_reply.started":"2025-12-30T02:44:39.588643Z","shell.execute_reply":"2025-12-30T02:44:39.601954Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"**Handle NA problem: None vs 0 vs Real missing**","metadata":{"_uuid":"c48f1f7f-973f-4f3f-9dc1-bc7861fcded5","_cell_guid":"f9619614-7fc5-48e6-8084-a3d3773891e4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"none_cols = [\n    \"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\",\n    \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\",\n    \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"MasVnrType\"\n]\n\ntrain[none_cols] = train[none_cols].fillna(\"None\")\ntest[none_cols] = test[none_cols].fillna(\"None\")\n\nzero_cols = [\"MasVnrArea\", \"GarageYrBlt\"]\n\ntrain[zero_cols] = train[zero_cols].fillna(0)\ntest[zero_cols] = test[zero_cols].fillna(0)\n\ntrain[\"LotFrontage\"] = train.groupby(\"Neighborhood\")[\"LotFrontage\"]\\\n                            .transform(lambda x: x.fillna(x.median()))\n\ntest[\"LotFrontage\"] = test.groupby(\"Neighborhood\")[\"LotFrontage\"]\\\n                          .transform(lambda x: x.fillna(x.median()))\n\ntrain[\"Electrical\"] = train[\"Electrical\"].fillna(\n    train[\"Electrical\"].mode()[0]\n)\ntest[\"Electrical\"] = test[\"Electrical\"].fillna(\n    train[\"Electrical\"].mode()[0]\n)","metadata":{"_uuid":"a66dfe36-9b9e-4034-9420-9f3ffdf09b39","_cell_guid":"84443458-9176-4427-97ae-0ec7f3770a4d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-30T02:44:39.604200Z","iopub.execute_input":"2025-12-30T02:44:39.604577Z","iopub.status.idle":"2025-12-30T02:44:39.654756Z","shell.execute_reply.started":"2025-12-30T02:44:39.604539Z","shell.execute_reply":"2025-12-30T02:44:39.653832Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"test_missing = test.isna().sum()\ntest_missing = test_missing[test_missing > 0].sort_values(ascending=False)\n\ncat_cols = [\n    \"MSZoning\", \"Utilities\", \"Functional\",\n    \"Exterior1st\", \"Exterior2nd\",\n    \"KitchenQual\", \"SaleType\"\n]\n\nfor col in cat_cols:\n    test[col] = test[col].fillna(train[col].mode()[0])\n\nnum_zero_cols = [\n    \"BsmtFullBath\", \"BsmtHalfBath\",\n    \"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\",\n    \"TotalBsmtSF\",\n    \"GarageCars\", \"GarageArea\"\n]\n\nfor col in num_zero_cols:\n    test[col] = test[col].fillna(0)\n","metadata":{"_uuid":"478b6ae5-b173-4d16-a53f-c7536b12c7b1","_cell_guid":"978e5a27-3e56-4a08-9cd7-7acfbaafba8c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-30T02:44:39.656841Z","iopub.execute_input":"2025-12-30T02:44:39.657203Z","iopub.status.idle":"2025-12-30T02:44:39.682249Z","shell.execute_reply.started":"2025-12-30T02:44:39.657173Z","shell.execute_reply":"2025-12-30T02:44:39.680860Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"y = train[\"SalePrice\"].copy()\n\n#Train/test feature split\nX_train = train.drop(\"SalePrice\", axis=1)\nX_test  = test.copy()\n# Concentrate before dummy encoding\nX_all = pd.concat([X_train, X_test], axis=0, ignore_index=True)\n# dummy encoding\nX_all_encoded = pd.get_dummies(X_all)\n\n# Split back into train/test encoded\nX_train_enc = X_all_encoded.iloc[:len(X_train), :]\nX_test_enc  = X_all_encoded.iloc[len(X_train):, :]\n\nX_train_enc = X_train_enc.fillna(0)\nX_test_enc  = X_test_enc.fillna(0)\ny_log = np.log(y)\nX = X_train_enc.copy()\nprint(X_train_enc.shape)\nX_test_enc.shape","metadata":{"_uuid":"c8aaeda1-984b-49d2-8b24-14eb39b4ef70","_cell_guid":"f4639118-8394-4deb-a9bc-8db82130f15c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-30T02:44:39.685004Z","iopub.execute_input":"2025-12-30T02:44:39.685375Z","iopub.status.idle":"2025-12-30T02:44:39.758492Z","shell.execute_reply.started":"2025-12-30T02:44:39.685340Z","shell.execute_reply":"2025-12-30T02:44:39.757483Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"(1460, 303)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(1459, 303)"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Phase 1: Linear models","metadata":{}},{"cell_type":"markdown","source":"## Simple Linear Regression with K-fold CV","metadata":{"_uuid":"ad3b471d-83e8-43f1-a52b-4a84a9c4deb8","_cell_guid":"320fd962-cbc4-438c-a6f7-04af90e0bab6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split\n\n\ny_log = np.log(y)\ntX = X_train_enc.copy()\n\n# KFold setup !!!!\nkf = KFold(n_splits=10, shuffle=True, random_state=42)\n\nmodel = LinearRegression()\n\nscores = cross_val_score(\n    model,\n    X,\n    y_log,\n    cv=kf,\n    scoring=\"neg_root_mean_squared_error\"\n)\n\nrmse_scores = -scores\nprint(\"OLS 10-Fold RMSE (log scale):\")\nprint(\"Fold RMSE:\", rmse_scores)\nprint(\"Mean RMSE:\", rmse_scores.mean())\nprint(\"Std  RMSE:\", rmse_scores.std())","metadata":{"_uuid":"46b70c95-c090-4073-aadf-b811611040ea","_cell_guid":"1e419920-ad71-45ec-995b-bc292794bc7f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-30T02:44:39.759598Z","iopub.execute_input":"2025-12-30T02:44:39.759916Z","iopub.status.idle":"2025-12-30T02:44:41.158336Z","shell.execute_reply.started":"2025-12-30T02:44:39.759862Z","shell.execute_reply":"2025-12-30T02:44:41.157484Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"OLS 10-Fold RMSE (log scale):\nFold RMSE: [0.11818827 0.15100814 0.13021239 0.12735436 0.19174033 0.25304027\n 0.18153506 0.11448518 0.12137219 0.09236675]\nMean RMSE: 0.1481302916018943\nStd  RMSE: 0.045430030119244444\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"**Interpretation: OLS**\n- OLS is unstable with ~300 one-hot features → high variance across folds.\n- Regularization reduces variance and stabilizes CV.","metadata":{}},{"cell_type":"markdown","source":"### Next: Ridge regression\nRidge + GridSearchCV ---> Full K-fold CV + Alpha tuning","metadata":{"_uuid":"80e457e7-ea15-4928-9e09-37a5e102bb5e","_cell_guid":"a68b6570-26b0-4973-ab9c-e1f1d8c8ddf0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\n\nridge_pipe = Pipeline([\n    (\"scaler\", StandardScaler(with_mean=False)),  \n    (\"ridge\", Ridge())\n])\n\n\nparam_grid = {\n    \"ridge__alpha\": np.logspace(-3, 3, 50)  \n}\n\ngrid = GridSearchCV(\n    ridge_pipe,\n    param_grid=param_grid,\n    scoring=\"neg_root_mean_squared_error\",\n    cv=kf,\n    n_jobs=-1\n)\n\ngrid.fit(X, y_log)\n\nbest_alpha = grid.best_params_[\"ridge__alpha\"]\nbest_rmse  = -grid.best_score_\n\nprint(\"Best alpha:\", best_alpha)\nprint(\"Best 10-fold RMSE (log scale):\", best_rmse)","metadata":{"_uuid":"6deaede0-06f3-4574-a2d8-fd078c4ad193","_cell_guid":"957b8ab5-6a41-42f3-94da-4ff333feae9d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-30T02:44:41.159418Z","iopub.execute_input":"2025-12-30T02:44:41.159903Z","iopub.status.idle":"2025-12-30T02:44:54.003007Z","shell.execute_reply.started":"2025-12-30T02:44:41.159871Z","shell.execute_reply":"2025-12-30T02:44:54.002252Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Best alpha: 429.1934260128778\nBest 10-fold RMSE (log scale): 0.13888309472698798\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## OLS vs Ridge Coefficient shrinkage inspection\n- OLS = unbiased but unstable under multicollinearity\n- Ridge = biased but lower variance\n- Bias–variance trade-off ","metadata":{"_uuid":"cba51a0c-b2ac-442d-9754-0c66d21e5a58","_cell_guid":"cc4bd0d6-c875-4210-8d7a-8219d7cda884","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"X = X_train_enc.copy()\ny_log = np.log(train[\"SalePrice\"])\n\n\nols_pipe = Pipeline([\n    (\"scaler\", StandardScaler(with_mean=False)),\n    (\"ols\", LinearRegression())\n])\n\nols_pipe.fit(X, y_log)\n\n\nbeta_ols = ols_pipe.named_steps[\"ols\"].coef_\nfeatures = X.columns\n\n\nbest_model = grid.best_estimator_\n\nbeta_ridge = best_model.named_steps[\"ridge\"].coef_\nbest_alpha = best_model.named_steps[\"ridge\"].alpha\n\nprint(\"Best alpha used:\", best_alpha)\n\ncoef_df = pd.DataFrame({\n    \"feature\": features,\n    \"beta_ols\": beta_ols,\n    \"beta_ridge\": beta_ridge\n})\n\ncoef_df[\"abs_ols\"] = coef_df[\"beta_ols\"].abs()\ncoef_df[\"abs_ridge\"] = coef_df[\"beta_ridge\"].abs()\n\n# shrink ratio: how much magnitude remains after ridge\n# add tiny number to avoid divide-by-zero explosions\neps = 1e-12\ncoef_df[\"shrink_ratio\"] = coef_df[\"abs_ridge\"] / (coef_df[\"abs_ols\"] + eps)\n\n\nbig_in_ols = coef_df[coef_df[\"abs_ols\"] > 0.05].copy()\n\n\nbig_in_ols.sort_values(\"shrink_ratio\", ascending=True).head(25)","metadata":{"_uuid":"11722abb-581e-43d8-8bdf-ef746f9cdbb4","_cell_guid":"2a42bc5d-0145-4d20-babb-085d9d6262a4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-30T02:44:54.003941Z","iopub.execute_input":"2025-12-30T02:44:54.004234Z","iopub.status.idle":"2025-12-30T02:44:54.133864Z","shell.execute_reply.started":"2025-12-30T02:44:54.004204Z","shell.execute_reply":"2025-12-30T02:44:54.133032Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Best alpha used: 429.1934260128778\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"              feature  beta_ols  beta_ridge   abs_ols  abs_ridge  shrink_ratio\n25        GarageYrBlt -0.132255    0.002351  0.132255   0.002351      0.017776\n33           PoolArea  0.067427    0.004827  0.067427   0.004827      0.071592\n6           YearBuilt  0.052409    0.012404  0.052409   0.012404      0.236678\n16          GrLivArea  0.066072    0.037909  0.066072   0.037909      0.573754\n126  RoofMatl_ClyTile -0.065999   -0.038929  0.065999   0.038929      0.589841\n4         OverallQual  0.056505    0.040005  0.056505   0.040005      0.707995","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>beta_ols</th>\n      <th>beta_ridge</th>\n      <th>abs_ols</th>\n      <th>abs_ridge</th>\n      <th>shrink_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25</th>\n      <td>GarageYrBlt</td>\n      <td>-0.132255</td>\n      <td>0.002351</td>\n      <td>0.132255</td>\n      <td>0.002351</td>\n      <td>0.017776</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>PoolArea</td>\n      <td>0.067427</td>\n      <td>0.004827</td>\n      <td>0.067427</td>\n      <td>0.004827</td>\n      <td>0.071592</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>YearBuilt</td>\n      <td>0.052409</td>\n      <td>0.012404</td>\n      <td>0.052409</td>\n      <td>0.012404</td>\n      <td>0.236678</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>GrLivArea</td>\n      <td>0.066072</td>\n      <td>0.037909</td>\n      <td>0.066072</td>\n      <td>0.037909</td>\n      <td>0.573754</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>RoofMatl_ClyTile</td>\n      <td>-0.065999</td>\n      <td>-0.038929</td>\n      <td>0.065999</td>\n      <td>0.038929</td>\n      <td>0.589841</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OverallQual</td>\n      <td>0.056505</td>\n      <td>0.040005</td>\n      <td>0.056505</td>\n      <td>0.040005</td>\n      <td>0.707995</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## LASSO: Variable selection","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nlasso_pipe = Pipeline([\n    (\"scaler\", StandardScaler(with_mean=False)),\n    (\"lasso\", Lasso(max_iter=10000))\n])\n\n\n## α tuning with K-fold CV\nparam_grid = {\n    \"lasso__alpha\": np.logspace(-4, 1, 50)  \n}\n\nlasso_grid = GridSearchCV(\n    lasso_pipe,\n    param_grid=param_grid,\n    scoring=\"neg_root_mean_squared_error\",\n    cv=kf,\n    n_jobs=-1\n)\n\nlasso_grid.fit(X, y_log)\n\nbest_alpha_lasso = lasso_grid.best_params_[\"lasso__alpha\"]\nbest_rmse_lasso  = -lasso_grid.best_score_\n\nprint(\"Best Lasso alpha:\", best_alpha_lasso)\nprint(\"Best Lasso 10-fold RMSE (log):\", best_rmse_lasso)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:44:54.135704Z","iopub.execute_input":"2025-12-30T02:44:54.136053Z","iopub.status.idle":"2025-12-30T02:45:17.979845Z","shell.execute_reply.started":"2025-12-30T02:44:54.136021Z","shell.execute_reply":"2025-12-30T02:45:17.978809Z"}},"outputs":[{"name":"stdout","text":"Best Lasso alpha: 0.005428675439323859\nBest Lasso 10-fold RMSE (log): 0.1373247185196936\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"**Lasso Inspection**","metadata":{}},{"cell_type":"code","source":"best_lasso = lasso_grid.best_estimator_\nbeta_lasso = best_lasso.named_steps[\"lasso\"].coef_\n\nn_total = len(beta_lasso)\nn_zero  = np.sum(beta_lasso == 0)\nn_nonzero = n_total - n_zero\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:45:17.981028Z","iopub.execute_input":"2025-12-30T02:45:17.981535Z","iopub.status.idle":"2025-12-30T02:45:17.987715Z","shell.execute_reply.started":"2025-12-30T02:45:17.981504Z","shell.execute_reply":"2025-12-30T02:45:17.986536Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"coef_df[\"beta_lasso\"] = beta_lasso\ncoef_df[\"abs_lasso\"]  = coef_df[\"beta_lasso\"].abs()\nridge_kept_lasso_dropped = coef_df[\n    (coef_df[\"abs_ridge\"] > 1e-4) &\n    (coef_df[\"abs_lasso\"] == 0)\n].sort_values(\"abs_ridge\", ascending=False)\n\n## Table comparing Lasso and Ridge coefficients: what they shrank, what they kept/ killed\nridge_kept_lasso_dropped.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:45:17.988952Z","iopub.execute_input":"2025-12-30T02:45:17.989375Z","iopub.status.idle":"2025-12-30T02:45:18.017867Z","shell.execute_reply.started":"2025-12-30T02:45:17.989333Z","shell.execute_reply":"2025-12-30T02:45:18.016994Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"               feature  beta_ols  beta_ridge   abs_ols  abs_ridge  \\\n13            1stFlrSF  0.040240    0.030395  0.040240   0.030395   \n23        TotRmsAbvGrd  0.007472    0.021813  0.007472   0.021813   \n14            2ndFlrSF  0.043516    0.018512  0.043516   0.018512   \n21        BedroomAbvGr  0.005266    0.009688  0.005266   0.009688   \n133   RoofMatl_WdShngl  0.005693    0.008593  0.005693   0.008593   \n40         MSZoning_RL  0.007790    0.008534  0.007790   0.008534   \n188        BsmtQual_TA -0.003545   -0.008485  0.003545   0.008485   \n8           MasVnrArea  0.001484    0.006596  0.001484   0.006596   \n114  HouseStyle_1Story -0.004772   -0.006547  0.004772   0.006547   \n178  Foundation_BrkTil -0.007089   -0.006451  0.007089   0.006451   \n\n     shrink_ratio  beta_lasso  abs_lasso  \n13       0.755339         0.0        0.0  \n23       2.919254         0.0        0.0  \n14       0.425397         0.0        0.0  \n21       1.839802         0.0        0.0  \n133      1.509528         0.0        0.0  \n40       1.095474         0.0        0.0  \n188      2.393382        -0.0        0.0  \n8        4.444737         0.0        0.0  \n114      1.372025        -0.0        0.0  \n178      0.909897        -0.0        0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>beta_ols</th>\n      <th>beta_ridge</th>\n      <th>abs_ols</th>\n      <th>abs_ridge</th>\n      <th>shrink_ratio</th>\n      <th>beta_lasso</th>\n      <th>abs_lasso</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13</th>\n      <td>1stFlrSF</td>\n      <td>0.040240</td>\n      <td>0.030395</td>\n      <td>0.040240</td>\n      <td>0.030395</td>\n      <td>0.755339</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>TotRmsAbvGrd</td>\n      <td>0.007472</td>\n      <td>0.021813</td>\n      <td>0.007472</td>\n      <td>0.021813</td>\n      <td>2.919254</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2ndFlrSF</td>\n      <td>0.043516</td>\n      <td>0.018512</td>\n      <td>0.043516</td>\n      <td>0.018512</td>\n      <td>0.425397</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>BedroomAbvGr</td>\n      <td>0.005266</td>\n      <td>0.009688</td>\n      <td>0.005266</td>\n      <td>0.009688</td>\n      <td>1.839802</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>RoofMatl_WdShngl</td>\n      <td>0.005693</td>\n      <td>0.008593</td>\n      <td>0.005693</td>\n      <td>0.008593</td>\n      <td>1.509528</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>MSZoning_RL</td>\n      <td>0.007790</td>\n      <td>0.008534</td>\n      <td>0.007790</td>\n      <td>0.008534</td>\n      <td>1.095474</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>BsmtQual_TA</td>\n      <td>-0.003545</td>\n      <td>-0.008485</td>\n      <td>0.003545</td>\n      <td>0.008485</td>\n      <td>2.393382</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>MasVnrArea</td>\n      <td>0.001484</td>\n      <td>0.006596</td>\n      <td>0.001484</td>\n      <td>0.006596</td>\n      <td>4.444737</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>HouseStyle_1Story</td>\n      <td>-0.004772</td>\n      <td>-0.006547</td>\n      <td>0.004772</td>\n      <td>0.006547</td>\n      <td>1.372025</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>Foundation_BrkTil</td>\n      <td>-0.007089</td>\n      <td>-0.006451</td>\n      <td>0.007089</td>\n      <td>0.006451</td>\n      <td>0.909897</td>\n      <td>-0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"### Elastic Net = Ridge + Lasso","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\n\nenet_pipe = Pipeline([\n    (\"scaler\", StandardScaler(with_mean=False)),\n    (\"enet\", ElasticNet(max_iter=100000, tol=1e-3, warm_start=True))\n])\n\nparam_grid_enet = {\n    \"enet__alpha\": np.logspace(-3, 2, 30),      # 0.001 ... 100  (more stable than 1e-4..10)\n    \"enet__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]\n}\n\nenet_grid = GridSearchCV(\n    enet_pipe,\n    param_grid=param_grid_enet,\n    scoring=\"neg_root_mean_squared_error\",\n    cv=kf,\n    n_jobs=-1\n)\n\nenet_grid.fit(X, y_log)\n\nbest_alpha_enet = enet_grid.best_params_[\"enet__alpha\"]\nbest_l1_ratio   = enet_grid.best_params_[\"enet__l1_ratio\"]\nbest_rmse_enet  = -enet_grid.best_score_\n\nprint(\"Best ElasticNet alpha:\", best_alpha_enet)\nprint(\"Best ElasticNet l1_ratio:\", best_l1_ratio)\nprint(\"Best ElasticNet 10-fold RMSE (log):\", best_rmse_enet)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:45:18.019103Z","iopub.execute_input":"2025-12-30T02:45:18.019412Z","iopub.status.idle":"2025-12-30T02:45:54.033062Z","shell.execute_reply.started":"2025-12-30T02:45:18.019385Z","shell.execute_reply":"2025-12-30T02:45:54.031789Z"}},"outputs":[{"name":"stdout","text":"Best ElasticNet alpha: 0.0529831690628371\nBest ElasticNet l1_ratio: 0.1\nBest ElasticNet 10-fold RMSE (log): 0.13614026744090554\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"ols_pipe = Pipeline([\n    (\"scaler\", StandardScaler(with_mean=False)),\n    (\"ols\", LinearRegression())\n])\n\nlin_models = [\n    (\"OLS\", ols_pipe, \"no regularization\"),\n    (\"Ridge\", grid.best_estimator_, f\"alpha={grid.best_params_['ridge__alpha']:.3g}\"),\n    (\"Lasso\", lasso_grid.best_estimator_, f\"alpha={lasso_grid.best_params_['lasso__alpha']:.3g}\"),\n    (\"Elastic Net\", enet_grid.best_estimator_,\n     f\"alpha={enet_grid.best_params_['enet__alpha']:.3g}, l1={enet_grid.best_params_['enet__l1_ratio']}\")\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:45:54.036677Z","iopub.execute_input":"2025-12-30T02:45:54.036983Z","iopub.status.idle":"2025-12-30T02:45:54.043168Z","shell.execute_reply.started":"2025-12-30T02:45:54.036956Z","shell.execute_reply":"2025-12-30T02:45:54.042055Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Phase 2: Nonlinear Model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n\nrf = RandomForestRegressor(random_state=42, n_jobs=-1)\n\nparam_grid = {\n    \"n_estimators\": [300, 350],\n    \"max_features\": [\"sqrt\", 0.3],\n    \"min_samples_leaf\": [1, 2]\n}\n\nrf_grid = GridSearchCV(\n    rf,\n    param_grid=param_grid,\n    scoring=\"neg_root_mean_squared_error\",\n    cv=kf,\n    n_jobs=-1\n)\n\nrf_grid.fit(X, y_log)\n\nprint(\"Best params:\", rf_grid.best_params_)\nprint(\"Best CV mean RMSE:\", -rf_grid.best_score_)\nbest_rf = rf_grid.best_estimator_\nrf.fold = -cross_val_score(best_rf, X, y_log, cv=kf,\n                        scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:45:54.044299Z","iopub.execute_input":"2025-12-30T02:45:54.044645Z","iopub.status.idle":"2025-12-30T02:48:12.227340Z","shell.execute_reply.started":"2025-12-30T02:45:54.044616Z","shell.execute_reply":"2025-12-30T02:48:12.226340Z"}},"outputs":[{"name":"stdout","text":"Best params: {'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 350}\nBest CV mean RMSE: 0.13535157016539978\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Best: n_estimators=350\n      max_features=0.3\n      min_samples_leaf=1\nCV RMSE ≈ 0.1354\nstd ≈ 0.021\n","metadata":{}},{"cell_type":"code","source":"rows = []\nfor name, mdl, note in lin_models:\n    scores = cross_val_score(\n        mdl, X, y_log,\n        cv=kf,\n        scoring=\"neg_root_mean_squared_error\",\n        n_jobs=-1\n    )\n    rmse = -scores\n    rows.append({\n        \"Model\": name,\n        \"CV_RMSE_mean\": rmse.mean(),\n        \"CV_RMSE_std\": rmse.std(),\n        \"Notes\": note\n    })\n\n\nrows.append({\n    \"Model\": \"Random Forest\",\n    \"CV_RMSE_mean\": rf.fold.mean(),\n    \"CV_RMSE_std\": rf.fold.std(),\n    \"Notes\": \"n_estimators=300, max_features=0.3, min_samples_leaf=1\"\n})\n\nresults = pd.DataFrame(rows).sort_values(\"CV_RMSE_mean\")\nresults\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:48:12.228611Z","iopub.execute_input":"2025-12-30T02:48:12.229241Z","iopub.status.idle":"2025-12-30T02:48:13.408543Z","shell.execute_reply.started":"2025-12-30T02:48:12.229198Z","shell.execute_reply":"2025-12-30T02:48:13.407648Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"           Model  CV_RMSE_mean  CV_RMSE_std  \\\n4  Random Forest      0.135352     0.020926   \n3    Elastic Net      0.136140     0.045422   \n2          Lasso      0.137325     0.048920   \n1          Ridge      0.138883     0.036051   \n0            OLS      0.146358     0.043875   \n\n                                               Notes  \n4  n_estimators=300, max_features=0.3, min_sample...  \n3                                alpha=0.053, l1=0.1  \n2                                      alpha=0.00543  \n1                                          alpha=429  \n0                                  no regularization  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>CV_RMSE_mean</th>\n      <th>CV_RMSE_std</th>\n      <th>Notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>Random Forest</td>\n      <td>0.135352</td>\n      <td>0.020926</td>\n      <td>n_estimators=300, max_features=0.3, min_sample...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Elastic Net</td>\n      <td>0.136140</td>\n      <td>0.045422</td>\n      <td>alpha=0.053, l1=0.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lasso</td>\n      <td>0.137325</td>\n      <td>0.048920</td>\n      <td>alpha=0.00543</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ridge</td>\n      <td>0.138883</td>\n      <td>0.036051</td>\n      <td>alpha=429</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>OLS</td>\n      <td>0.146358</td>\n      <td>0.043875</td>\n      <td>no regularization</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"### Boosting\n- build many small trees sequentially, each new tree tries to fix the mistakes (residuals) of the current model.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\n\ngbr = GradientBoostingRegressor(random_state=42)\n\nparam_grid = {\n    \"learning_rate\": [0.1],\n    \"n_estimators\": [1200],\n    \"max_depth\": [2]\n}\n\ngbr_grid = GridSearchCV(\n    gbr,\n    param_grid=param_grid,\n    scoring=\"neg_root_mean_squared_error\",\n    cv=kf,\n    n_jobs=-1\n)\n\ngbr_grid.fit(X, y_log)\n\nprint(\"Best params:\", gbr_grid.best_params_)\nprint(\"Best CV RMSE:\", -gbr_grid.best_score_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:48:13.409765Z","iopub.execute_input":"2025-12-30T02:48:13.410174Z","iopub.status.idle":"2025-12-30T02:49:11.392228Z","shell.execute_reply.started":"2025-12-30T02:48:13.410142Z","shell.execute_reply":"2025-12-30T02:49:11.386211Z"}},"outputs":[{"name":"stdout","text":"Best params: {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 1200}\nBest CV RMSE: 0.12196243627146534\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"best_gbr = gbr_grid.best_estimator_\ngbr_scores = cross_val_score(\n    best_gbr, X, y_log,\n    cv=kf,\n    scoring=\"neg_root_mean_squared_error\",\n    n_jobs=-1\n)\ngbr_rmse = -gbr_scores  # convert to positive RMSE\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:49:11.394086Z","iopub.execute_input":"2025-12-30T02:49:11.394541Z","iopub.status.idle":"2025-12-30T02:49:56.555875Z","shell.execute_reply.started":"2025-12-30T02:49:11.394497Z","shell.execute_reply":"2025-12-30T02:49:56.554840Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"rows.append({\n    \"Model\": \"Gradient Boosting\",\n    \"CV_RMSE_mean\": gbr_rmse.mean(),\n    \"CV_RMSE_std\": gbr_rmse.std(),\n    \"Notes\": (\n        f\"n_estimators={gbr_grid.best_params_['n_estimators']}, \"\n        f\"lr={gbr_grid.best_params_['learning_rate']}, \"\n        f\"max_depth={gbr_grid.best_params_['max_depth']}\"\n    )\n})\n\n\nresults = pd.DataFrame(rows).sort_values(\"CV_RMSE_mean\")\nresults\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:49:56.556963Z","iopub.execute_input":"2025-12-30T02:49:56.557275Z","iopub.status.idle":"2025-12-30T02:49:56.570456Z","shell.execute_reply.started":"2025-12-30T02:49:56.557246Z","shell.execute_reply":"2025-12-30T02:49:56.569323Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"               Model  CV_RMSE_mean  CV_RMSE_std  \\\n5  Gradient Boosting      0.121962     0.019890   \n4      Random Forest      0.135352     0.020926   \n3        Elastic Net      0.136140     0.045422   \n2              Lasso      0.137325     0.048920   \n1              Ridge      0.138883     0.036051   \n0                OLS      0.146358     0.043875   \n\n                                               Notes  \n5             n_estimators=1200, lr=0.1, max_depth=2  \n4  n_estimators=300, max_features=0.3, min_sample...  \n3                                alpha=0.053, l1=0.1  \n2                                      alpha=0.00543  \n1                                          alpha=429  \n0                                  no regularization  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>CV_RMSE_mean</th>\n      <th>CV_RMSE_std</th>\n      <th>Notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>Gradient Boosting</td>\n      <td>0.121962</td>\n      <td>0.019890</td>\n      <td>n_estimators=1200, lr=0.1, max_depth=2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Random Forest</td>\n      <td>0.135352</td>\n      <td>0.020926</td>\n      <td>n_estimators=300, max_features=0.3, min_sample...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Elastic Net</td>\n      <td>0.136140</td>\n      <td>0.045422</td>\n      <td>alpha=0.053, l1=0.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lasso</td>\n      <td>0.137325</td>\n      <td>0.048920</td>\n      <td>alpha=0.00543</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ridge</td>\n      <td>0.138883</td>\n      <td>0.036051</td>\n      <td>alpha=429</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>OLS</td>\n      <td>0.146358</td>\n      <td>0.043875</td>\n      <td>no regularization</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"### XGboost","metadata":{}},{"cell_type":"markdown","source":"#### Hyperparameter tuning:\n- I used a stepwise coarse-to-fine search to tune XGBoost efficiently.\n- I first searched the learning dynamics (learning_rate, n_estimators), then tuned sampling for generalization (subsample, colsample_bytree), and finally adjusted regularization / split constraints (reg_lambda, min_child_weight, plus optional gamma/reg_alpha).\n- After selecting the best combination, I refit the final model and report the final 10-fold CV RMSE .\n- Full stepwise grid-search logs are kept in the analysis notes for reproducibility.\n","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\nfinal_params = dict(\n    objective=\"reg:squarederror\",\n    random_state=42,\n    n_jobs=-1,\n    tree_method=\"hist\",\n\n    max_depth=3,\n    learning_rate=0.05,\n    n_estimators=1000,\n\n    subsample=0.85,\n    colsample_bytree=0.70,\n\n    min_child_weight=1,\n    reg_lambda=1,\n    gamma=0,\n    reg_alpha=0,\n)\n\nfinal_model = XGBRegressor(**final_params)\nfinal_model.fit(X, y_log)\n\nscores = cross_val_score(final_model, X, y_log, cv=kf,\n                         scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\nxgb_rmse = -scores\nprint(\"Final 10-fold mean:\", xgb_rmse.mean(), \"std:\", xgb_rmse.std())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:49:56.571588Z","iopub.execute_input":"2025-12-30T02:49:56.571882Z","iopub.status.idle":"2025-12-30T02:50:07.200089Z","shell.execute_reply.started":"2025-12-30T02:49:56.571855Z","shell.execute_reply":"2025-12-30T02:50:07.199152Z"}},"outputs":[{"name":"stdout","text":"Final 10-fold mean: 0.11754785535786746 std: 0.0192754743575291\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"rows.append({\n    \"Model\": \"XGBoost\",\n    \"CV_RMSE_mean\": xgb_rmse.mean(),\n    \"CV_RMSE_std\": xgb_rmse.std(),\n    \"Notes\": \"n_estimators=1000, max_depth=3,learning_rate=0.05\"\n})\n\nresults = pd.DataFrame(rows).sort_values(\"CV_RMSE_mean\")\nresults\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:50:07.201147Z","iopub.execute_input":"2025-12-30T02:50:07.201521Z","iopub.status.idle":"2025-12-30T02:50:07.214935Z","shell.execute_reply.started":"2025-12-30T02:50:07.201484Z","shell.execute_reply":"2025-12-30T02:50:07.213946Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"               Model  CV_RMSE_mean  CV_RMSE_std  \\\n6            XGBoost      0.117548     0.019275   \n5  Gradient Boosting      0.121962     0.019890   \n4      Random Forest      0.135352     0.020926   \n3        Elastic Net      0.136140     0.045422   \n2              Lasso      0.137325     0.048920   \n1              Ridge      0.138883     0.036051   \n0                OLS      0.146358     0.043875   \n\n                                               Notes  \n6  n_estimators=1000, max_depth=3,learning_rate=0.05  \n5             n_estimators=1200, lr=0.1, max_depth=2  \n4  n_estimators=300, max_features=0.3, min_sample...  \n3                                alpha=0.053, l1=0.1  \n2                                      alpha=0.00543  \n1                                          alpha=429  \n0                                  no regularization  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>CV_RMSE_mean</th>\n      <th>CV_RMSE_std</th>\n      <th>Notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>XGBoost</td>\n      <td>0.117548</td>\n      <td>0.019275</td>\n      <td>n_estimators=1000, max_depth=3,learning_rate=0.05</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Gradient Boosting</td>\n      <td>0.121962</td>\n      <td>0.019890</td>\n      <td>n_estimators=1200, lr=0.1, max_depth=2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Random Forest</td>\n      <td>0.135352</td>\n      <td>0.020926</td>\n      <td>n_estimators=300, max_features=0.3, min_sample...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Elastic Net</td>\n      <td>0.136140</td>\n      <td>0.045422</td>\n      <td>alpha=0.053, l1=0.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lasso</td>\n      <td>0.137325</td>\n      <td>0.048920</td>\n      <td>alpha=0.00543</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ridge</td>\n      <td>0.138883</td>\n      <td>0.036051</td>\n      <td>alpha=429</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>OLS</td>\n      <td>0.146358</td>\n      <td>0.043875</td>\n      <td>no regularization</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"xgb_rmse_mean = xgb_rmse.mean()\nxgb_rmse_sd = xgb_rmse.std()\nxgb_summary = pd.DataFrame({\n    \"Metric\": [\n        \"Model\",\n        \"CV RMSE (mean)\",\n        \"CV RMSE (std)\",\n        \"max_depth\",\n        \"learning_rate\",\n        \"n_estimators\",\n        \"subsample\",\n        \"colsample_bytree\",\n        \"min_child_weight\",\n        \"reg_lambda\",\n        \"gamma\",\n        \"reg_alpha\",\n        \"tree_method\",\n    ],\n    \"Value\": [\n        \"XGBoost\",\n        f\"{xgb_rmse_mean:.6f}\",\n        f\"{xgb_rmse_sd:.6f}\",\n        final_params[\"max_depth\"],\n        final_params[\"learning_rate\"],\n        final_params[\"n_estimators\"],\n        final_params[\"subsample\"],\n        final_params[\"colsample_bytree\"],\n        final_params[\"min_child_weight\"],\n        final_params[\"reg_lambda\"],\n        final_params[\"gamma\"],\n        final_params[\"reg_alpha\"],\n        final_params[\"tree_method\"],\n    ]\n})\n\nxgb_summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:56:15.796679Z","iopub.execute_input":"2025-12-30T02:56:15.797103Z","iopub.status.idle":"2025-12-30T02:56:15.809566Z","shell.execute_reply.started":"2025-12-30T02:56:15.797050Z","shell.execute_reply":"2025-12-30T02:56:15.808598Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"              Metric     Value\n0              Model   XGBoost\n1     CV RMSE (mean)  0.117548\n2      CV RMSE (std)  0.019275\n3          max_depth         3\n4      learning_rate      0.05\n5       n_estimators      1000\n6          subsample      0.85\n7   colsample_bytree       0.7\n8   min_child_weight         1\n9         reg_lambda         1\n10             gamma         0\n11         reg_alpha         0\n12       tree_method      hist","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Model</td>\n      <td>XGBoost</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CV RMSE (mean)</td>\n      <td>0.117548</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CV RMSE (std)</td>\n      <td>0.019275</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max_depth</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>learning_rate</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>n_estimators</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>subsample</td>\n      <td>0.85</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>colsample_bytree</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>min_child_weight</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>reg_lambda</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>gamma</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>reg_alpha</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>tree_method</td>\n      <td>hist</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"params = final_params.copy() \n\n\nxgb_final = XGBRegressor(**params)\nxgb_final.fit(X, y_log)\n\ny_test_log = xgb_final.predict(X_test_enc)\ny_test = np.exp(y_test_log)\n\nsubmission = pd.DataFrame({\n    \"Id\": test[\"Id\"],\n    \"SalePrice\": y_test\n})\nsubmission.to_csv(\"submission_xgb.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T02:50:07.238225Z","iopub.status.idle":"2025-12-30T02:50:07.238588Z","shell.execute_reply.started":"2025-12-30T02:50:07.238398Z","shell.execute_reply":"2025-12-30T02:50:07.238416Z"}},"outputs":[],"execution_count":null}]}